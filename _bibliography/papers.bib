---
---

@article{clip_as_rnn,
      title={CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor}, 
      author={Shuyang Sun and Runjia Li and Philip Torr and Xiuye Gu and Siyang Li},
      year={2023},
      eprint={2312.07661},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      journal={arXiv preprint arXiv:2312.07661},
      selected=true,
      pdf=https://arxiv.org/pdf/2312.07661.pdf,
      bibtex_show={true},
website=https://torrvision.com/clip_as_rnn/,
code=https://github.com/kevin-ssy/CLIP_as_RNN,
preview=clip_as_rnn.jpg,
highlight=true
}

@article{sun2023remax,
  title={ReMaX: Relaxing for better training on efficient panoptic segmentation},
  author={Sun, Shuyang and Wang, Weijun and Yu, Qihang and Howard, Andrew and Torr, Philip and Chen, Liang-Chieh},
  journal={NeurIPS},
  year={2023},
  selected=true,
  bibtex_show={true},
  pdf=https://arxiv.org/pdf/2306.17319.pdf,
  website=https://nips.cc/virtual/2023/poster/71598,
  preview=remax.jpg
}

@inproceedings{li2023oxfordtvg,
  title={OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?},
  author={Li*, Runjia and Sun*, Shuyang and Elhoseiny, Mohamed and Torr, Philip},
  booktitle={ICCV},
  pages={20293--20303},
  year={2023},
  bibtex_show={true},
}

@article{yuan2023real,
  title={Real-Fake: Effective Training Data Synthesis Through Distribution Matching},
  author={Yuan, Jianhao and Zhang, Jie and Sun, Shuyang and Torr, Philip and Zhao, Bo},
  journal={arXiv preprint arXiv:2310.10402},
  year={2023},
  bibtex_show={true},
  selected=true,
  preview=realfake.jpg,
  website=https://torrvision.com/realfake/,
  pdf=https://arxiv.org/abs/2310.10402
}


@inproceedings{zhou2022slot,
  title={Slot-vps: Object-centric representation learning for video panoptic segmentation},
  author={Zhou, Yi and Zhang, Hui and Lee, Hana and Sun, Shuyang and Li, Pingjun and Zhu, Yangguang and Yoo, ByungIn and Qi, Xiaojuan and Han, Jae-Joon},
  booktitle={CVPR},
  pages={3093--3103},
  year={2022},
      bibtex_show={true},
}

@inproceedings{he2022knowledge,
  title={Knowledge distillation as efficient pre-training: Faster convergence, higher data-efficiency, and better transferability},
  author={He, Ruifei and Sun, Shuyang and Yang, Jihan and Bai, Song and Qi, Xiaojuan},
  booktitle={CVPR},
  pages={9161--9171},
  year={2022},
      bibtex_show={true},
}

@article{he2022synthetic,
  title={Is synthetic data from generative models ready for image recognition?},
  author={He, Ruifei and Sun, Shuyang and Yu, Xin and Xue, Chuhui and Zhang, Wenqing and Torr, Philip and Bai, Song and Qi, Xiaojuan},
  journal={ICLR},
  year={2023},
      bibtex_show={true},
  selected=true,
  code=https://github.com/CVMI-Lab/SyntheticData,
  pdf=https://arxiv.org/abs/2210.07574,
  preview=synthesis.png
}

@article{sun2022lumix,
  title={Lumix: Improving mixup by better modelling label uncertainty},
  author={Sun*, Shuyang and Chen*, Jie-Neng and He, Ruifei and Yuille, Alan and Torr, Philip and Bai, Song},
  journal={ICASSP},
  year={2024},
      bibtex_show={true},
}

@article{sun2022patch,
  title={Patch-based separable transformer for visual recognition},
  author={Sun, Shuyang and Yue, Xiaoyu and Zhao, Hengshuang and Torr, Philip and Bai, Song},
  journal={T-PAMI},
  year={2022},
  publisher={IEEE},
      bibtex_show={true},
}


@article{chen2021transmix,
  title={TransMix: Attend to Mix for Vision Transformers},
  author={Sun*, Shuyang and Chen*, Jie-Neng and He, Ju and Torr, Philip and Yuille, Alan and Bai, Song},
  journal={CVPR},
  year={2021},
  selected=true,
      bibtex_show={true},
pdf=https://arxiv.org/pdf/2111.09833.pdf,
code=https://github.com/Beckschen/TransMix,
preview=transmix.jpg
}

@article{sun2021visual,
  title={Visual Parser: Representing Part-whole Hierarchies with Transformers},
  author={Sun, Shuyang and Yue, Xiaoyu and Bai, Song and Torr, Philip},
  journal={arXiv preprint arXiv:2107.05790},
  year={2021},
      bibtex_show={true},
  selected=true,
  preview=vip.png,
  pdf=https://arxiv.org/abs/2107.05790,
  code=https://github.com/kevin-ssy/ViP
}

@inproceedings{yue2021vision,
  title={Vision transformer with progressive sampling},
  author={Yue*, Xiaoyu and Sun*, Shuyang and Kuang, Zhanghui and Wei, Meng and Torr, Philip and Zhang, Wayne and Lin, Dahua},
  booktitle={ICCV},
  pages={387--396},
  year={2021},
      bibtex_show={true},
  selected=true,
  preview=psvit.png,
  pdf=https://arxiv.org/abs/2108.01684,
  code=https://github.com/yuexy/PS-ViT
}

@inproceedings{sun2021aggregation,
  title={Aggregation with Feature Detection},
  author={Sun, Shuyang and Yue, Xiaoyu and Qi, Xiaojuan and Ouyang, Wanli and Prisacariu, Victor Adrian and Torr, Philip},
  booktitle={ICCV},
  pages={527--536},
  year={2021},
      bibtex_show={true},
}



@article{zhou2020exploring,
  title={Exploring the hierarchy in relation labels for scene graph generation},
  author={Zhou, Yi and Sun, Shuyang and Zhang, Chao and Li, Yikang and Ouyang, Wanli},
  journal={arXiv preprint arXiv:2009.05834},
  year={2020},
      bibtex_show={true},
}

@article{sun2020learning,
  title={Learning to sample the most useful training patches from images},
  author={Sun, Shuyang and Chen, Liang and Slabaugh, Gregory and Torr, Philip},
  journal={arXiv preprint arXiv:2011.12097},
  year={2020},
      bibtex_show={true},
}


@inproceedings{chen2019hybrid,
  title={Hybrid task cascade for instance segmentation},
  author={Chen, Kai and Pang, Jiangmiao and Wang, Jiaqi and Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and Liu, Ziwei and Shi, Jianping and Ouyang, Wanli and others},
  booktitle={CVPR},
  pages={4974--4983},
  year={2019},
      bibtex_show={true},
}

@article{chen2019mmdetection,
  title={MMDetection: Open mmlab detection toolbox and benchmark},
  author={Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and Liu, Ziwei and Xu, Jiarui and others},
  journal={arXiv preprint arXiv:1906.07155},
  year={2019},
      bibtex_show={true},
}

@inproceedings{zhang2019robust,
  title={Robust multi-modality multi-object tracking},
  author={Zhang, Wenwei and Zhou, Hui and Sun, Shuyang and Wang, Zhe and Shi, Jianping and Loy, Chen Change},
  booktitle={ICCV},
  pages={2365--2374},
  year={2019},
      bibtex_show={true},
}




@article{sun2018fishnet,
  title={Fishnet: A versatile backbone for image, region, and pixel level prediction},
  author={Sun, Shuyang and Pang, Jiangmiao and Shi, Jianping and Yi, Shuai and Ouyang, Wanli},
  journal={NeurIPS},
  volume={31},
  year={2018},
      bibtex_show={true},
selected=true,
pdf=https://arxiv.org/pdf/1901.03495.pdf,
code=https://github.com/kevin-ssy/FishNet,
preview=fish.png
}

@inproceedings{sun2018optical,
  title={Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition},
  author={Sun, Shuyang and Kuang, Zhanghui and Sheng, Lu and Ouyang, Wanli and Zhang, Wei},
  booktitle={CVPR},
  year={2018},
  bibtex_show={true},
  selected=true,
pdf=https://arxiv.org/pdf/1711.11152.pdf,
code=https://github.com/kevin-ssy/Optical-Flow-Guided-Feature,
preview=off.jpg
}

@inproceedings{zhao2017spindle,
  title={Spindle net: Person re-identification with human body region guided feature decomposition and fusion},
  author={Zhao, Haiyu and Tian, Maoqing and Sun, Shuyang and Shao, Jing and Yan, Junjie and Yi, Shuai and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={CVPR},
  pages={1077--1085},
  year={2017},
      bibtex_show={true},
}
